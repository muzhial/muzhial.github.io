<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="keywords" content="Hexo Theme Keep">
    <meta name="description" content="应无所住而生其心">
    <meta name="author" content="muzhi :) 木之">
    
    <title>
        
            verl 解读 - ray 相关前置知识 (part1) |
        
        muzhi.al
    </title>
    
<link rel="stylesheet" href="/css/style.css">

    
        <link rel="shortcut icon" href="/images/logo.png">
    
    
<link rel="stylesheet" href="/font/css/fontawesome.min.css">

    
<link rel="stylesheet" href="/font/css/regular.min.css">

    
<link rel="stylesheet" href="/font/css/solid.min.css">

    
<link rel="stylesheet" href="/font/css/brands.min.css">

    
    <script class="keep-theme-configurations">
    const KEEP = window.KEEP || {}
    KEEP.hexo_config = {"hostname":"example.com","root":"/","language":"en"}
    KEEP.theme_config = {"toc":{"enable":false,"number":false,"expand_all":false,"init_open":true,"layout":"right"},"style":{"primary_color":"#0066cc","logo":"/images/logo.png","favicon":"/images/logo.png","avatar":"/images/favicon-192x192.png","first_screen":{"enable":false,"header_transparent":false,"background_img":"/images/bg.svg","description":"应无所住而生其心","hitokoto":false},"scroll":{"progress_bar":false,"percent":false}},"local_search":{"enable":false,"preload":false},"code_block":{"tools":{"enable":false,"style":"default"},"highlight_theme":"default"},"pjax":{"enable":false},"lazyload":{"enable":false},"comment":{"enable":false,"use":"valine","valine":{"appid":null,"appkey":null,"server_urls":null,"placeholder":null},"gitalk":{"github_id":null,"github_admins":null,"repository":null,"client_id":null,"client_secret":null,"proxy":null},"twikoo":{"env_id":null,"region":null,"version":"1.6.21"},"waline":{"server_url":null,"reaction":false,"version":2},"giscus":{"repo":null,"repo_id":null,"category":"Announcements","category_id":null,"reactions_enabled":false}},"post":{"author_label":{"enable":false,"auto":false,"custom_label_list":["Trainee","Engineer","Architect"]},"word_count":{"wordcount":true,"min2read":false},"datetime_format":"YYYY-MM-DD","copyright_info":false,"share":false,"reward":{"enable":false,"img_link":null,"text":null}},"website_count":{"busuanzi_count":{"enable":false,"site_uv":false,"site_pv":false,"page_pv":false}},"version":"3.8.2"}
    KEEP.language_ago = {"second":"%s seconds ago","minute":"%s minutes ago","hour":"%s hours ago","day":"%s days ago","week":"%s weeks ago","month":"%s months ago","year":"%s years ago"}
    KEEP.language_code_block = {"copy":"Copy code","copied":"Copied","fold":"Fold code block","folded":"Folded"}
    KEEP.language_copy_copyright = {"copy":"Copy copyright info","copied":"Copied","title":"Original article title","author":"Original article author","link":"Original article link"}
  </script>
<meta name="generator" content="Hexo 6.3.0"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style><link rel="alternate" href="/atom.xml" title="木之" type="application/atom+xml">
</head>


<body>
<div class="progress-bar-container">
    

    
</div>


<main class="page-container border-box">

    <!-- home first screen  -->
    

    <!-- page content -->
    <div class="page-main-content border-box">
        <div class="page-main-content-top">
            
<header class="header-wrapper">

    <div class="border-box header-content">
        <div class="left border-box">
            
                <a class="logo-image border-box" href="/">
                    <img src="/images/logo.png">
                </a>
            
            <a class="site-name border-box" href="/">
               muzhi.al
            </a>
        </div>

        <div class="right border-box">
            <div class="pc">
                <ul class="menu-list">
                    
                        <li class="menu-item">
                            <a class=""
                               href="/"
                            >
                                主页
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/archives"
                            >
                                归档
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/slice"
                            >
                                断章
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/about"
                            >
                                关于
                            </a>
                        </li>
                    
                    
                </ul>
            </div>
            <div class="mobile">
                
                <div class="icon-item menu-bar">
                    <div class="menu-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <div class="header-drawer">
        <ul class="drawer-menu-list">
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/">主页</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/archives">归档</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/slice">断章</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/about">关于</a>
                </li>
            
        </ul>
    </div>

    <div class="window-mask"></div>

</header>


        </div>

        <div class="page-main-content-middle border-box">

            <div class="main-content border-box">

                

                    <div class="fade-in-down-animation">
    <div class="post-page-container border-box">

        <div class="article-content-container border-box">

            

            <div class="article-content-bottom border-box">
                
                    <div class="article-title">
                        verl 解读 - ray 相关前置知识 (part1)
                    </div>
                

                
                    <div class="article-header border-box">
                        <!-- 
                            <div class="avatar-box border-box">
                                <img src="/images/favicon-192x192.png">
                            </div>
                         -->
                        <div class="info-box">
                            <!-- <div class="author">
                                <span class="name">muzhi :) 木之</span>
                                
                            </div> -->
                            <div class="meta-info border-box">
                                

<div class="article-meta-info-container border-box post">
    <div class="article-meta-info border-box">
        


        
            <span class="meta-info-item article-create-date">
                <i class="icon fa-solid fa-calendar-check"></i>&nbsp;
                <span class="pc">2025-06-17</span>
                <span class="mobile">2025-06-17 00:48</span>
            </span>

            <!-- <span class="meta-info-item article-update-date">
                <i class="icon fa-solid fa-file-pen"></i>&nbsp;
                <span class="pc" data-updated="Mon Jun 23 2025 22:20:07 GMT+0800">2025-06-23</span>
            </span> -->
        

        
            <span class="meta-info-item article-category border-box"><i class="icon fas fa-folder"></i>&nbsp;
                <ul class="article-category-ul">
                    
                            <li class="category-item"><a href="/categories/infra/">infra</a></li>
                        
                    
                </ul>
            </span>
        

        
            <span class="article-tag meta-info-item border-box">
                <i class="icon fas fa-tags"></i>&nbsp;
                <ul class="article-tag-ul">
                    
                            <li class="tag-item"><span class="tag-separator"><i class="icon fas fa-hashtag"></i></span><a href="/tags/RL/">RL</a></li>
                        
                    
                            <li class="tag-item"><span class="tag-separator"><i class="icon fas fa-hashtag"></i></span><a href="/tags/verl/">verl</a></li>
                        
                    
                            <li class="tag-item"><span class="tag-separator"><i class="icon fas fa-hashtag"></i></span><a href="/tags/Ray/">Ray</a></li>
                        
                    
                </ul>
            </span>
        

        
        
            <span class="meta-info-item article-wordcount">
                <i class="icon fas fa-file-word"></i>&nbsp;<span>1.5k Words</span>
            </span>
        
        
        
    </div>

    
</div>

                            </div>
                        </div>
                    </div>
                

                <div class="article-content keep-markdown-body">
                    

                    <h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p><a class="link" target="_blank" rel="noopener" href="https://github.com/volcengine/verl">verl</a> 强化学习框架依赖于分布式计算框架 <a class="link" target="_blank" rel="noopener" href="https://docs.ray.io/en/latest/index.html">Ray</a>。Ray 相关的基础知识是理解 verl 代码的基础。</p>
<p>本文是关于 Ray <a class="link" target="_blank" rel="noopener" href="https://docs.ray.io/en/latest/ray-core/actors.html">Actors</a> 的一些基础操作说明。覆盖的内容：</p>
<ul>
<li>定义一个 <code>Actors</code>，其初始化一个 <code>torch model</code>；</li>
<li><code>Actors</code> 初始化一个分布式进程组 (<code>torch.distributed.init_process_group</code>)；</li>
<li>实现一个简易的 DP (Data Parallel) forward 和 backward 计算，backward 后进行不同 GPU 间的 grad 同步。</li>
</ul>
<h2 id="示例代码阐释"><a href="#示例代码阐释" class="headerlink" title="示例代码阐释"></a>示例代码阐释</h2><p>完整程序如下，详细说明见代码中的注释。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> traceback</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> socket</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.distributed <span class="keyword">as</span> dist</span><br><span class="line"><span class="keyword">import</span> ray</span><br><span class="line"><span class="keyword">from</span> ray.util.placement_group <span class="keyword">import</span> placement_group, remove_placement_group</span><br><span class="line"><span class="keyword">from</span> ray.util.scheduling_strategies <span class="keyword">import</span> PlacementGroupSchedulingStrategy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">find_free_port</span>():</span><br><span class="line">    <span class="string">"""Find a free port for master communication"""</span></span><br><span class="line">    <span class="keyword">import</span> socket</span><br><span class="line">    <span class="keyword">with</span> socket.socket(socket.AF_INET, socket.SOCK_STREAM) <span class="keyword">as</span> s:</span><br><span class="line">        s.bind((<span class="string">""</span>, <span class="number">0</span>))</span><br><span class="line">        s.listen(<span class="number">1</span>)</span><br><span class="line">        port = s.getsockname()[<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">return</span> port</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">set_random_seed</span>(<span class="params">seed=<span class="number">42</span></span>):</span><br><span class="line">    random.seed(seed)</span><br><span class="line">    np.random.seed(seed)</span><br><span class="line">    torch.manual_seed(seed)</span><br><span class="line">    <span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">        torch.cuda.manual_seed(seed)</span><br><span class="line">        torch.cuda.manual_seed_all(seed)</span><br><span class="line"></span><br><span class="line">set_random_seed(<span class="number">42</span>)</span><br><span class="line">ray.init()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DummyAttn</span>(nn.Module):</span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    定义一个简单的 model，完成 forward，backward，梯度同步等操作。</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        num_heads: <span class="built_in">int</span> = <span class="number">16</span>,</span></span><br><span class="line"><span class="params">        head_dim: <span class="built_in">int</span> = <span class="number">64</span>,</span></span><br><span class="line"><span class="params">        hidden_size: <span class="built_in">int</span> = <span class="number">1024</span>,</span></span><br><span class="line"><span class="params">    </span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        self.num_heads = num_heads</span><br><span class="line">        self.head_dim = head_dim</span><br><span class="line">        self.q_proj = nn.Linear(hidden_size, head_dim * num_heads, bias=<span class="literal">False</span>)</span><br><span class="line">        self.k_proj = nn.Linear(hidden_size, head_dim * num_heads, bias=<span class="literal">False</span>)</span><br><span class="line">        self.v_proj = nn.Linear(hidden_size, head_dim * num_heads, bias=<span class="literal">False</span>)</span><br><span class="line">        self.out_proj = nn.Linear(head_dim * num_heads, hidden_size, bias=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">        self._init_weights()</span><br><span class="line">        <span class="comment"># ---------------------</span></span><br><span class="line">        <span class="comment"># 为 `requires_grad=True` 的 tensor 注册梯度同步的 hook</span></span><br><span class="line">        <span class="comment"># backward 完成梯度计算后，自动调用</span></span><br><span class="line">        <span class="comment"># ---------------------</span></span><br><span class="line">        self.register_backward_hook(self._allreduce_grads)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_init_weights</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> self.modules():</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Linear):</span><br><span class="line">                nn.init.xavier_uniform_(m.weight)</span><br><span class="line">                <span class="keyword">if</span> m.bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                    nn.init.zeros_(m.bias)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">register_backward_hook</span>(<span class="params">self, hook</span>):</span><br><span class="line">        <span class="keyword">for</span> p <span class="keyword">in</span> self.parameters():</span><br><span class="line">            <span class="keyword">if</span> p.requires_grad <span class="keyword">is</span> <span class="literal">True</span>:</span><br><span class="line">                p.register_hook(hook)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_allreduce_grads</span>(<span class="params">self, grad</span>):</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        在当前 group (default group) 中执行梯度 all_reduce 同步操作。</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        dist.all_reduce(grad, op=dist.ReduceOp.SUM)</span><br><span class="line">        <span class="comment"># grad /= world_size</span></span><br><span class="line">        <span class="keyword">return</span> grad</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            x: (batch_size, seq_len, hidden_size)</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        bs, seq_len, hidden_size = x.size()</span><br><span class="line">        q = self.q_proj(x)</span><br><span class="line">        k = self.k_proj(x)</span><br><span class="line">        v = self.v_proj(x)</span><br><span class="line"></span><br><span class="line">        q = q.view(bs, seq_len, self.num_heads, self.head_dim).transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">        k = k.view(bs, seq_len, self.num_heads, self.head_dim).permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">        v = v.view(bs, seq_len, self.num_heads, self.head_dim).transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        attn = q @ k / math.sqrt(self.head_dim)  <span class="comment"># equal `torch.matmul`</span></span><br><span class="line">        attn_scores = F.softmax(attn, dim=-<span class="number">1</span>)</span><br><span class="line">        y = attn_scores @ v</span><br><span class="line">        y = y.transpose(<span class="number">1</span>, <span class="number">2</span>).contiguous().view(bs, seq_len, -<span class="number">1</span>)</span><br><span class="line">        y = self.out_proj(y)</span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">WorkerBase</span>:</span><br><span class="line">    <span class="string">""" 用作 Actors 的类</span></span><br><span class="line"><span class="string">    可以直接使用装饰器定义 @ray.remote 或者 ray.remote(WorkerBase)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, temp_init: <span class="built_in">bool</span> = <span class="literal">False</span></span>):</span><br><span class="line">        self._node_id = ray.get_runtime_context().get_node_id()</span><br><span class="line">        self._actor_id = ray.get_runtime_context().get_actor_id()</span><br><span class="line">        self._task_id = ray.get_runtime_context().get_task_id()</span><br><span class="line">        self._job_id = ray.get_runtime_context().get_job_id()</span><br><span class="line">        self._hostname = socket.gethostname()</span><br><span class="line">        self._ip_address = socket.gethostbyname(socket.gethostname())</span><br><span class="line">        <span class="keyword">if</span> temp_init:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        <span class="comment"># ---------------------</span></span><br><span class="line">        <span class="comment"># 注意：</span></span><br><span class="line">        <span class="comment"># 因为每个 actor 会启用自己的进程空间，如果需要随机种子，需要在 actor 内部设置。</span></span><br><span class="line">        <span class="comment"># ---------------------</span></span><br><span class="line">        self._set_seed(<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># ---------------------</span></span><br><span class="line">        <span class="comment"># 和 pytorch 中定义分布式训练流程差不多</span></span><br><span class="line">        <span class="comment"># ---------------------</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> dist.is_initialized():</span><br><span class="line">            dist.init_process_group(</span><br><span class="line">                backend=<span class="string">"cpu:gloo,cuda:nccl"</span>,</span><br><span class="line">                world_size=<span class="built_in">int</span>(os.getenv(<span class="string">"WORLD_SIZE"</span>, <span class="string">"1"</span>)),</span><br><span class="line">                rank=<span class="built_in">int</span>(os.getenv(<span class="string">"RANK"</span>, <span class="string">"0"</span>)),</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">        self._rank = dist.get_rank()</span><br><span class="line">        self._world_size = dist.get_world_size()</span><br><span class="line">        <span class="comment"># print(f"=&gt; Rank {self._rank}/{self._world_size}")</span></span><br><span class="line"></span><br><span class="line">        self.model = DummyAttn()</span><br><span class="line">        <span class="comment"># ---------------------</span></span><br><span class="line">        <span class="comment"># 注意：</span></span><br><span class="line">        <span class="comment"># 因为 Ray 的资源调度，cuda index 的设置需要注意，</span></span><br><span class="line">        <span class="comment"># 此处，如果当前 actor 使用 1 CPU，1 GPU，则在当前 actor 只能看到 1 个 GPU，</span></span><br><span class="line">        <span class="comment"># 假设启动当前这个脚本时，指定了 CUDA_VISIBLE_DEVICES=0,2,3。</span></span><br><span class="line">        <span class="comment"># 则，在启动的 3 个 actor 中分别获取 CUDA_VISIBLE_DEVICES，</span></span><br><span class="line">        <span class="comment"># Rank:0 -&gt; CUDA_VISIBLE_DEVICES=0</span></span><br><span class="line">        <span class="comment"># Rank:1 -&gt; CUDA_VISIBLE_DEVICES=2</span></span><br><span class="line">        <span class="comment"># Rank:2 -&gt; CUDA_VISIBLE_DEVICES=3</span></span><br><span class="line">        <span class="comment"># ---------------------</span></span><br><span class="line">        self.model.to(<span class="string">"cuda"</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f"=&gt; Rank <span class="subst">{self._rank}</span> init model"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_actor_info</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> {</span><br><span class="line">            <span class="string">"node_id"</span>: self._node_id,</span><br><span class="line">            <span class="string">"actor_id"</span>: self._actor_id,</span><br><span class="line">            <span class="string">"task_id"</span>: self._task_id,</span><br><span class="line">            <span class="string">"job_id"</span>: self._job_id,</span><br><span class="line">            <span class="string">"hostname"</span>: self._hostname,</span><br><span class="line">            <span class="string">"ip_address"</span>: self._ip_address,</span><br><span class="line">        }</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">shutdown</span>(<span class="params">self</span>):</span><br><span class="line">        dist.destroy_process_group()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_set_seed</span>(<span class="params">self, seed: <span class="built_in">int</span> = <span class="number">42</span></span>):</span><br><span class="line">        set_random_seed(seed)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">train_step</span>(<span class="params">self, data</span>):</span><br><span class="line">        self.model.train()</span><br><span class="line"></span><br><span class="line">        x = data.to(<span class="string">"cuda"</span>)</span><br><span class="line">        y = self.model(x)</span><br><span class="line">        loss = y.<span class="built_in">sum</span>()</span><br><span class="line">        loss.backward()</span><br><span class="line">        <span class="keyword">return</span> loss.cpu()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">sample_grads</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">for</span> name, p <span class="keyword">in</span> self.model.named_parameters():</span><br><span class="line">            <span class="keyword">if</span> p.requires_grad <span class="keyword">is</span> <span class="literal">True</span>:</span><br><span class="line">                <span class="comment"># print(f"=&gt; Rank {self._rank} grad: {p.grad}")</span></span><br><span class="line">                <span class="keyword">return</span> name, p.grad.cpu()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    num_devices = get_num_devices()</span><br><span class="line">    <span class="comment"># ---------------------</span></span><br><span class="line">    <span class="comment"># placement group 的 Scheduling，</span></span><br><span class="line">    <span class="comment"># 参考：https://docs.ray.io/en/latest/ray-core/scheduling/placement-group.html</span></span><br><span class="line">    <span class="comment"># ---------------------</span></span><br><span class="line">    pg = placement_group([</span><br><span class="line">        {<span class="string">"CPU"</span>: <span class="number">1</span>, <span class="string">"GPU"</span>: <span class="number">1</span>} <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_devices)</span><br><span class="line">    ], strategy=<span class="string">"STRICT_PACK"</span>, name=<span class="string">"ray_actor_communication"</span>)</span><br><span class="line"></span><br><span class="line">    ray.get(pg.ready())</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f"=&gt; Placement group <span class="subst">{pg.<span class="built_in">id</span>}</span> is ready, num_devices: <span class="subst">{num_devices}</span>"</span>)</span><br><span class="line">    worker_cls = WorkerBase</span><br><span class="line">    <span class="comment"># ---------------------</span></span><br><span class="line">    <span class="comment"># WorkerBase 普通类 -&gt; Ray Actors</span></span><br><span class="line">    <span class="comment"># ---------------------</span></span><br><span class="line">    Worker = ray.remote(worker_cls)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># ---------------------</span></span><br><span class="line">    <span class="comment"># 以下部分主要是为了获取 actor 的 ip，并设置 "MASTER_ADDR"，"MASTER_PORT"，pytorch 分布式进程组初始化时需要。</span></span><br><span class="line">    <span class="comment"># 实现上比较丑陋，不用过多关注。</span></span><br><span class="line">    <span class="comment"># ---------------------</span></span><br><span class="line">    <span class="comment"># Create a temporary rank 0 worker just to get network info</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">"========= Get network info =========="</span>)</span><br><span class="line">    temp_worker = Worker.options(</span><br><span class="line">        scheduling_strategy=PlacementGroupSchedulingStrategy(</span><br><span class="line">            placement_group=pg,</span><br><span class="line">            placement_group_bundle_index=<span class="number">0</span>,</span><br><span class="line">        ),</span><br><span class="line">        runtime_env={<span class="string">"env_vars"</span>: {<span class="string">"WORLD_SIZE"</span>: <span class="string">"1"</span>, <span class="string">"RANK"</span>: <span class="string">"0"</span>, <span class="string">"MASTER_ADDR"</span>: <span class="string">"127.0.0.1"</span>, <span class="string">"MASTER_PORT"</span>: <span class="built_in">str</span>(find_free_port())}},</span><br><span class="line">        num_gpus=<span class="number">1</span>,</span><br><span class="line">        num_cpus=<span class="number">1</span>,</span><br><span class="line">    ).remote(temp_init=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Get master address</span></span><br><span class="line">    network_info = ray.get(temp_worker.get_actor_info.remote())</span><br><span class="line">    master_addr = network_info[<span class="string">"ip_address"</span>]</span><br><span class="line">    master_port = <span class="built_in">str</span>(find_free_port())</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f"Using master: <span class="subst">{master_addr}</span>:<span class="subst">{master_port}</span>"</span>)</span><br><span class="line">    <span class="comment"># Terminate temporary worker</span></span><br><span class="line">    ray.kill(temp_worker)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">"========= Terminate temporary worker ==========\n"</span>)</span><br><span class="line"></span><br><span class="line">    workers = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_devices):</span><br><span class="line">        env_vars = {</span><br><span class="line">            <span class="string">"WORLD_SIZE"</span>: <span class="built_in">str</span>(num_devices),</span><br><span class="line">            <span class="string">"RANK"</span>: <span class="built_in">str</span>(i),</span><br><span class="line">            <span class="string">"MASTER_ADDR"</span>: master_addr,</span><br><span class="line">            <span class="string">"MASTER_PORT"</span>: master_port,</span><br><span class="line">        }</span><br><span class="line"></span><br><span class="line">        workers.append(</span><br><span class="line">            <span class="comment"># ------------------</span></span><br><span class="line">            <span class="comment"># WorkerBase 类的初始化，并分配和绑定调度资源</span></span><br><span class="line">            <span class="comment"># ------------------</span></span><br><span class="line">            Worker.options(</span><br><span class="line">                scheduling_strategy=PlacementGroupSchedulingStrategy(</span><br><span class="line">                    placement_group=pg,</span><br><span class="line">                    placement_group_bundle_index=i,</span><br><span class="line">                ),</span><br><span class="line">                runtime_env={</span><br><span class="line">                    <span class="string">"env_vars"</span>: env_vars,</span><br><span class="line">                },</span><br><span class="line">                num_gpus=<span class="number">1</span>,</span><br><span class="line">                num_cpus=<span class="number">1</span>,</span><br><span class="line">            ).remote()</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># ------ test ------</span></span><br><span class="line">    <span class="comment"># for worker in workers:</span></span><br><span class="line">    <span class="comment">#     print(f"Worker {ray.get(worker.get_actor_info.remote())}")</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># ------ train ------</span></span><br><span class="line">    datas = torch.randn(<span class="number">4</span>, <span class="number">128</span>, <span class="number">1024</span>)</span><br><span class="line">    <span class="keyword">for</span> i, worker <span class="keyword">in</span> <span class="built_in">enumerate</span>(workers):</span><br><span class="line">        <span class="comment"># ----------------</span></span><br><span class="line">        <span class="comment"># 此处模拟 DP 操作</span></span><br><span class="line">        <span class="comment"># ----------------</span></span><br><span class="line">        data = datas.chunk(num_devices)[i]</span><br><span class="line">        worker.train_step.remote(data)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># ------ sample grads ------</span></span><br><span class="line">    grads = ray.get([worker.sample_grads.remote() <span class="keyword">for</span> worker <span class="keyword">in</span> workers])</span><br><span class="line">    <span class="keyword">for</span> i, (name, grad) <span class="keyword">in</span> <span class="built_in">enumerate</span>(grads):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f"=&gt; Rank <span class="subst">{i}</span> grad: <span class="subst">{name}</span>\n<span class="subst">{grad}</span>"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        main()</span><br><span class="line">    <span class="keyword">except</span> KeyboardInterrupt:</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(e)</span><br><span class="line">        traceback.print_exc()</span><br><span class="line">    <span class="keyword">finally</span>:</span><br><span class="line">        ray.shutdown()</span><br></pre></td></tr></table></figure>

<p>使用 2 GPUs 执行，即数据并行度为 2：<code>PYTHONUNBUFFERED=1 CUDA_VISIBLE_DEVICES=0,1 python &lt;this file&gt;</code></p>
<p>结果为：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">=&gt; Rank 0 grad: q_proj.weight</span><br><span class="line">tensor([[-3.8231,  0.4550,  5.1973,  ..., -1.1057,  0.7960,  3.6364],</span><br><span class="line">        [-6.1473, -6.2373, -0.2407,  ...,  2.4793, -4.6591, -3.9527],</span><br><span class="line">        [-1.2464, -1.6429, -0.6477,  ...,  1.6034,  0.2802,  3.2735],</span><br><span class="line">        ...,</span><br><span class="line">        [-1.1934,  0.6633, -4.8593,  ..., -2.4207,  0.7207, -3.9471],</span><br><span class="line">        [ 4.1377, 10.6296, -2.8300,  ..., -1.6472,  7.8439, -2.1861],</span><br><span class="line">        [ 0.5365, -1.7629,  4.4939,  ..., -0.6042, -7.0833, -1.4912]])</span><br><span class="line">=&gt; Rank 1 grad: q_proj.weight</span><br><span class="line">tensor([[-3.8231,  0.4550,  5.1973,  ..., -1.1057,  0.7960,  3.6364],</span><br><span class="line">        [-6.1473, -6.2373, -0.2407,  ...,  2.4793, -4.6591, -3.9527],</span><br><span class="line">        [-1.2464, -1.6429, -0.6477,  ...,  1.6034,  0.2802,  3.2735],</span><br><span class="line">        ...,</span><br><span class="line">        [-1.1934,  0.6633, -4.8593,  ..., -2.4207,  0.7207, -3.9471],</span><br><span class="line">        [ 4.1377, 10.6296, -2.8300,  ..., -1.6472,  7.8439, -2.1861],</span><br><span class="line">        [ 0.5365, -1.7629,  4.4939,  ..., -0.6042, -7.0833, -1.4912]])</span><br></pre></td></tr></table></figure>

<p>可以看到两张卡上的 model 梯度已经同步了。</p>
<p>然后使用 1 GPUs 执行，即数据并行度为 1：<code>PYTHONUNBUFFERED=1 CUDA_VISIBLE_DEVICES=0 python &lt;this file&gt;</code><br>结果为：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">=&gt; Rank 0 grad: q_proj.weight</span><br><span class="line">tensor([[-3.8231,  0.4550,  5.1973,  ..., -1.1057,  0.7960,  3.6364],</span><br><span class="line">        [-6.1473, -6.2373, -0.2407,  ...,  2.4793, -4.6591, -3.9527],</span><br><span class="line">        [-1.2464, -1.6429, -0.6477,  ...,  1.6034,  0.2802,  3.2735],</span><br><span class="line">        ...,</span><br><span class="line">        [-1.1934,  0.6633, -4.8593,  ..., -2.4207,  0.7207, -3.9471],</span><br><span class="line">        [ 4.1377, 10.6296, -2.8300,  ..., -1.6472,  7.8439, -2.1861],</span><br><span class="line">        [ 0.5365, -1.7629,  4.4939,  ..., -0.6042, -7.0833, -1.4912]])</span><br></pre></td></tr></table></figure>

<p>对比 GPUx1 和 GPUx2 的结果，是对齐的，验证了 DP 计算和梯度同步无误。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul>
<li>Ray docs. <a class="link" target="_blank" rel="noopener" href="https://docs.ray.io/en/latest/index.html">docs</a></li>
<li>HybridFlow: A Flexible and Efficient RLHF Framework. 2409. <a class="link" target="_blank" rel="noopener" href="https://arxiv.org/pdf/2409.19256v1">arxiv</a></li>
</ul>

                </div>

                

                <div class="post-bottom-tags-and-share border-box">
                    <div>
                        
                            <ul class="post-tags-box border-box">
                                
                                    <li class="tag-item border-box">
                                        <i class="icon fas fa-hashtag"></i>&nbsp;<a href="/tags/RL/">RL</a>
                                    </li>
                                
                                    <li class="tag-item border-box">
                                        <i class="icon fas fa-hashtag"></i>&nbsp;<a href="/tags/verl/">verl</a>
                                    </li>
                                
                                    <li class="tag-item border-box">
                                        <i class="icon fas fa-hashtag"></i>&nbsp;<a href="/tags/Ray/">Ray</a>
                                    </li>
                                
                            </ul>
                        
                    </div>
                    <div>
                        
                    </div>
                </div>

                

                
                    <div class="article-nav">
                        
                            <div class="article-prev">
                                <a class="prev"
                                   rel="prev"
                                   href="/2025/06/23/infra-verl-source-code-reading-2/"
                                   title="verl 解读 - Hybrid controller、WorkerGroup colocate 设计及源码分析 (part2)"
                                >
                                    <span class="left arrow-icon flex-center">
                                      <i class="fas fa-chevron-left"></i>
                                    </span>
                                            <span class="title flex-center">
                                        <span class="post-nav-title-item text-ellipsis">verl 解读 - Hybrid controller、WorkerGroup colocate 设计及源码分析 (part2)</span>
                                        <span class="post-nav-item">Prev posts</span>
                                    </span>
                                </a>
                            </div>
                        
                        
                            <div class="article-next">
                                <a class="next"
                                   rel="next"
                                   href="/2025/05/28/thoughts-boundaries-limits-of-language/"
                                   title="语言的界与边"
                                >
                                    <span class="title flex-center">
                                        <span class="post-nav-title-item text-ellipsis">语言的界与边</span>
                                        <span class="post-nav-item">Next posts</span>
                                    </span>
                                            <span class="right arrow-icon flex-center">
                                      <i class="fas fa-chevron-right"></i>
                                    </span>
                                </a>
                            </div>
                        
                    </div>
                

                
                    






                
            </div>
        </div>

        
    </div>
</div>


                
            </div>

        </div>

        <div class="page-main-content-bottom border-box">
            
<footer class="footer border-box">
    <div class="border-box website-info-box default">
        
            <div class="copyright-info info-item default">
                &copy;&nbsp;<span>2016</span>&nbsp;-&nbsp;2025
                
                    &nbsp;<i class="fas fa-heart icon-animate"></i>&nbsp;&nbsp;<a href="/">muzhi :) 木之</a>
                
            </div>

            <!-- <div class="theme-info info-item default">
                Powered by&nbsp;<a target="_blank" href="https://hexo.io">Hexo</a>&nbsp;&&nbsp;Theme&nbsp;<a class="keep-version" target="_blank" href="https://github.com/XPoet/hexo-theme-keep">Keep</a>
            </div> -->

            

            
        

        <div class="count-item info-item default">
            

            

            
        </div>
    </div>
</footer>

        </div>
    </div>

    <!-- post tools -->
    
        <div class="post-tools right-toc">
            <div class="post-tools-container border-box">
    <ul class="tools-list border-box">
        <!-- PC TOC show toggle -->
        

        <!-- PC go comment -->
        
    </ul>
</div>

        </div>
    

    <!-- side tools -->
    <div class="side-tools">
        <div class="side-tools-container border-box ">
    <ul class="side-tools-list side-tools-show-handle border-box">
        <li class="tools-item tool-font-adjust-plus flex-center">
            <i class="fas fa-search-plus"></i>
        </li>

        <li class="tools-item tool-font-adjust-minus flex-center">
            <i class="fas fa-search-minus"></i>
        </li>

        <li class="tools-item tool-dark-light-toggle flex-center">
            <i class="fas fa-moon"></i>
        </li>

        <!-- rss -->
        
            <li class="tools-item rss flex-center">
                <a class="flex-center"
                   href="/atom.xml"
                   target="_blank"
                >
                    <i class="fas fa-rss"></i>
                </a>
            </li>
        

        <li class="tools-item tool-scroll-to-bottom flex-center">
            <i class="fas fa-arrow-down"></i>
        </li>
    </ul>

    <ul class="exposed-tools-list border-box">
        

        

        <li class="tools-item tool-toggle-show flex-center">
            <i class="fas fa-cog fa-spin"></i>
        </li>

        <li class="tools-item tool-scroll-to-top flex-center show-arrow">
            <i class="arrow fas fa-arrow-up"></i>
            <span class="percent"></span>
        </li>
    </ul>
</div>

    </div>

    <!-- image mask -->
    <div class="zoom-in-image-mask">
    <img class="zoom-in-image">
</div>


    <!-- local search -->
    

    <!-- tablet toc -->
    
</main>



<!-- common -->

<script src="/js/utils.js"></script>

<script src="/js/header-shrink.js"></script>

<script src="/js/back2top.js"></script>

<script src="/js/dark-light-toggle.js"></script>

<script src="/js/main.js"></script>

<script src="/js/libs/anime.min.js"></script>


<!-- local-search -->


<!-- code-block -->


<!-- lazyload -->


<div class="">
    
        <!-- post-helper -->
        
<script src="/js/post/post-helper.js"></script>


        <!-- toc -->
        

        <!-- copyright-info -->
        

        <!-- share -->
        
    

    <!-- category-page -->
    

    <!-- links-page -->
    
</div>

<!-- pjax -->



</body>
</html>
